<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ShardingSphere - 博客</title>
    <link>https://shardingsphere.apache.org/blog/cn/</link>
    <description>Recent content on ShardingSphere - 博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://shardingsphere.apache.org/blog/cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ShardingSphere 与 openGauss 的化学反应</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/opengauss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/opengauss/</guid>
      <description>5月29日，由 openGauss 社区主办，北京鲲鹏联合创新中心、云和恩墨、深信服、SphereEx 合力承办的“【北京】openGauss Meetup”活动在北京海淀区中关村智能制造创新中心成功举行，此次 Meetup 也是 SphereEx 正式加入 openGauss 社区后的首次联合活动。在 Meetup 现场，SphereEx CEO 张亮从产品形态、部署架构、性能测试、未来规划等方面为大家带来了《ShardingSphere 与 openGauss 的化学反应》主题分享。
        </description>
    </item>
    
    <item>
      <title>停滞数年后，ElasticJob 携首个 Apache 版本 3.0.0-alpha 回归</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/alpha/</guid>
      <description>停滞数年后，ElasticJob 携首个 Apache 版本 3.0.0-alpha 回归 在成为 Apache ShardingSphere 的子项目的几个月时间里，ElasticJob 社区在修复与合并了535个 issue 和 pull request 之后，发布了加入 Apache 软件基金会后的第一个正式版本：3.0.0-alpha。
背景 ElasticJob（ https://github.com/apache/shardingsphere-elasticjob ）是面向互联网生态和海量任务的分布式调度解决方案，由两个相互独立的子项目 ElasticJob-Lite 和 ElasticJob-Cloud 组成。它诞生于 2015年，当时业界虽然有 QuartZ 等出类拔萃的定时任务框架，但缺乏分布式方面的探索。分布式调度云平台产品的缺失，使得 ElasticJob 从出现伊始便备受关注。它有效地弥补了作业在分布式领域的短板，并且提供了一站式的自动化运维管控端，各个产品使用统一的作业 API，开发者仅需一次开发，即可随意部署。
ElasticJob 在技术选型时，选择站在了巨人的肩膀上而不是重复制造轮子的理念，将定时任务事实标准的 QuartZ 与 分布式协调的利器 ZooKeeper 完美结合，快速而稳定的搭建了全新概念的分布式调度框架。
ElasticJob调度模型 ElasticJob 的调度模型划分为支持线程级别调度的进程内调度 ElasticJob-Lite，和进程级别调度的ElasticJob-Cloud。
进程内调度
ElasticJob-Lite 是面向进程内的线程级调度框架。它能够与 Spring 、Dubbo等 Java 框架配合使用，在作业中可自由使用 Spring 注入的 Bean，如数据源连接池、Dubbo 远程服务等，更加方便地贴合业务开发。
ElasticJob-Lite与业务应用部署在一起，其生命周期与业务应用保持一致，是典型的嵌入式轻量级架构。ElasticJob-Lite 非常适合于资源使用稳定、部署架构简单的普通 Java 应用，可以理解为 Java 开发框架。
ElasticJob-Lite 本身是无中心化架构，无需独立的中心化调度节点，分布式下的每个任务节点均是以自调度的方式适时的调度作业。任务之间只需要一个注册中心来对分布式场景下的任务状态进行协调即可，目前支持 ZooKeeper 作为注册中心。
架构图如下：
通过图中可看出，ElasticJob-Lite 的分布式作业节点通过选举获取主节点，并通过主节点进行分片。分片完毕后，主节点与从节点并无二致，均以自我调度的方式执行任务。
进程级调度
ElasticJob-Cloud 拥有进程内调度和进程级别调度两种方式。由于 ElasticJob-Cloud 能够对作业服务器的资源进行控制，因此其作业类型可划分为常驻任务和瞬时任务。常驻任务类似于ElasticJob-Lite，是进程内调度；瞬时任务则完全不同，它充分的利用了资源分配的削峰填谷能力，是进程级的调度，每次任务的会启动全新的进程处理。</description>
    </item>
    
    <item>
      <title>新版发布｜ShardingSphere 5.0.0-beta 来了！</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/ss_5.0.0beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/ss_5.0.0beta/</guid>
      <description>新版发布｜ShardingSphere 5.0.0-beta 来了！ Original 潘娟 SphereEx 6/22
 Apache ShardingSphere 5.0.0-beta 版在经过长达半年的筹备后，终于将在近期正式 Release! 本文将带领大家一同预览新版本即将带来哪些重大亮点功能。
 作者介绍  潘娟 | Trista
SphereEx 联合创始人
SphereEx co-founder, Apache member, Apache ShardingSphere PMC, Apache brpc(Incubating) mentor, 本次 Release manager。
前京东科技高级 DBA，曾负责京东数科数据库智能平台的设计与研发，现专注于分布式数据库 &amp;amp; 中间件生态及开源领域。被评为《2020 中国开源先锋人物》，多次受邀参加数据库 &amp;amp; 架构领域的相关会议分享。
 作为 Apache 的顶级项目，ShardingSphere 的 Release 要经过社区验证、投票、发布等环节，保证推出的版本符合 License 及 Apache Release 规范，且功能及项目层面尽可能符合预期，这是对项目本身及使用者的保护。当前版本已完成基本构建，预计本周内正式发行。
本次 Release 将会带来以下重要特性： 1. 亮点功能 全新定义的分布式数据库操作语言—DistSQL SQL 是一种用于存取数据以及查询、更新和管理关系数据库系统的数据库查询和程序设计语言。1986 年 10 月，美国国家标准学会将 SQL 作为关系式数据库管理系统的标准语言。现有通用数据库系统在其实践过程中都对 SQL 规范作了部分改写和扩充，具有更高灵活性和更丰富的功能，使其适用于自身的数据库系统。
DistSQL（Distributed SQL）是 Apache ShardingSphere 提出的，特有的一种内置 SQL 语言，能够提供标准 SQL 之外的增量功能操作能力。DistSQL 让用户可以像操作数据库一样操作 ShardingSphere，使其从面向开发人员的框架和中间件转变为面向运维人员的基础设施产品。</description>
    </item>
    
    <item>
      <title>【开源总动员】零基础入门Apache ShardingSphere开源之道</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/opensource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/opensource/</guid>
      <description>Apache SharingSphere是Apache基金会目前唯一的数据库中间件项目。它主要用于数据分片、分布式事务和分布式治理等分布式数据库相关场景。本次直播将分享为什么要参与开源；Apache开源软件基金会、Apache ShardingSphere核心原理及如何踏上开源之路。
        </description>
    </item>
    
    <item>
      <title>快讯！分布式调度项目ElasticJob即将重新起航</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/elasticjob/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/elasticjob/</guid>
      <description>快讯！分布式调度项目ElasticJob即将重新起航 ElasticJob是一个分布式调度解决方案，提供分布式任务的分片，弹性伸缩，全自动发现，基于时间驱动、数据驱动、常驻任务和临时任务的多任务类型，任务聚合和动态调配资源，故障检测、自动修复，失效转移和重试，完善的运维平台和管理工具，以及对云原生的良好支持等功能特性，可以全面满足企业对于任务管理和批量作业的调度处理能力。
ElasticJob自2014年底开源以来，经历了5年多的发展，以其功能的丰富性，文档的全面性，代码的高质量，框架的易用性，积累了大量的忠实用户和良好的业内口碑（5.8K star），一直也是分布式调度框架领域最受大家欢迎的项目之一。
近两年来，由于核心开发者全力发展和维护Apache ShardingSphere项目等原因，ElasticJob放缓了发展的脚步。但是随着Apache ShardingSphere项目在分布式领域的不断拓展，以及用户对于多数据集群环境的分布式管理和数据迁移的弹性扩容等功能，需要一个强大的分布式调度组件。由此为契机，Apache ShardingSphere社区已经计划发起提议将ElasticJob作为其子项目进行长期持续的更新和维护。
我们第一时间将此好消息公开，后续将带来更多关于ElasticJob的相关资讯。
 讨论邮件： https://lists.apache.org/thread.html/rd6171e2065be6bcfbeb7aba7e5c876eeed04db585c6ab78fc03a581c%40%3Cdev.shardingsphere.apache.org%3E
  捐赠Proposal： https://cwiki.apache.org/confluence/display/SHARDINGSPHERE/ElasticJob+Donation+Proposal
  社区讨论： https://github.com/elasticjob/elastic-job-lite/issues/728
 </description>
    </item>
    
    <item>
      <title>ShardingSphere的Apache共建之道</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/build/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/build/</guid>
      <description>Apache ShardingSphere项目VP&amp;ndash;张亮老师带来ShardingSphere项目与开源之道的精彩讲解。张亮，京东数科数据研发负责人，Apache ShardingSphere 发起人 &amp;amp; PPMC，JDTX 负责人。ShardingSphere 已经进入 Apache 孵化器，是京东集团首个进入 Apache 基金会的开源项目，也是 Apache 基金会首个分布式数据库中间件。
        </description>
    </item>
    
    <item>
      <title>分布式数据库解决方案Apache ShardingSphere毕业成为顶级项目</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/graduate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/graduate/</guid>
      <description>分布式数据库解决方案Apache ShardingSphere毕业成为顶级项目 全球最大的开源软件基金会 Apache 软件基金会（以下简称 Apache）于北京时间 2020年4 月 15 日宣布 Apache ShardingSphere毕业成为 Apache 顶级项目。
ShardingSphere于2018年11月10日捐赠给Apache并启动孵化。之后在导师的指导下，由孵化器管理委员会成员进行经营和孵化，在2020年3月28日在Apache孵化器以10 票支持一次性通过毕业提案投票。
4月15日，Apache董事会通过ShardingSphere毕业决议，结束了为期17个月的孵化，并由Apache 市场总监 Sally Khudairi在Apache软件基金会各渠道官号上发布官方通告。ShardingSphere是2020年度第一个从Apache孵化器毕业的顶级项目。
Apache ShardingSphere 是一款分布式数据库中间件，该项目由当当捐入 Apache，并在京东数科逐渐发展壮大，成为 业界首个Apache分布式数据库中间件项目。
毕业成为顶级项目见证了过去一年半来自Apache ShardingSphere 社区的努力，自从进入Apache孵化器以来，ShardingSphere已经从一个用于分片的JDBC驱动演变成为一个分布式生态系统。
感谢我们的导师、贡献者和Apache孵化器的支持。在冠状病毒爆发的这段时间里，社区仍然以多元化的方式积极运作。我们非常高兴的看到，项目由来自世界各地的120多位贡献者参与开发。</description>
    </item>
    
    <item>
      <title>从New SQL角度看Apache ShardingSphere</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/new_sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/new_sql/</guid>
      <description>近些年New SQL概念盛行，国内外各大公司对New SQL都有着不同的解读。博观而约取之后，本次分享将为大家带来有关New SQL理念、国内外产品架构的解读。并以New SQL的角度详细分析Apache ShardingSphere这一业界盛行的Apache开源分布式数据库中间件服务平台的架构、特性、规划及开源社区。
        </description>
    </item>
    
    <item>
      <title>我们是怎样打造一款分布式数据库的</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/database/</guid>
      <description>我们是怎样打造一款分布式数据库的 作者 | 张亮
关系型数据库在过去数十年的数据库领域一直占据着绝对主导的地位，它所带来的稳定性、安全性和易用性，成为了构建现代化系统的基石。随着的互联网高速发展，构架于单机系统的数据库已无法满足越来越高的并发请求和越来越大的数据存储需求，因此，分布式数据库被愈加广泛的采用。
一直以来，数据库领域均由西方的科技公司和社区所主导。而今，越来越多的国产数据库解决方案以分布式为支点，逐渐在此领域有所建树。Apache ShardingSphere 是其中的一个分布式数据库解决方案，也是目前 Apache 软件基金会中唯一的数据库中间件。 1 背景 全面兼容面向传统关系型数据库的 SQL 和事务，并且对分布式的天然友好，是分布式数据库解决方案的设计目标。它的核心功能主要集中在以下几点：
  分布式存储: 数据存储不受单机磁盘容量限制，可通过增加数据服务器的数量提升存储能力；
  计算存储分离: 计算节点无状态，可通过水平扩展增加算力。存储节点和计算节点能够分层优化；
  分布式事务: 高性能、完全支持本地事务 ACID 原义的分布式事务处理引擎；
  弹性伸缩：可以随时随地的在不影响现有应用的情况下，动态对数据存储节点扩容和缩容；
  强一致多副本：自动将数据以强一致、高性能的方式复制至跨机房的多个副本，以保证数据的绝对安全；
  HTAP：采用同一套产品混合处理 OLTP 的事务型操作和 OLAP 的分析型操作。
  分布式数据库的实现方案可以划分为进取型和稳定型。进取型实现方案是指开发全新架构的 NewSQL。这类产品以追求更高性能换取稳定性的缺失和运维经验的不足；稳定型的实现方案是指在现有数据库的基础上提供增量能力的中间件。这类产品则以牺牲部分性能以保证数据库的稳定性和运维经验的复用。
2 架构 Apache ShardingSphere 是一套开源的分布式数据库解决方案组成的生态圈，它由 Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar（计划中）这 3 款相互独立的产品组成。它们均提供标准化的数据水平扩展、分布式事务和分布式治理等功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。随着 Apache ShardingSphere 在查询优化器和分布式事务引擎的不断探索，它已渐渐地打破了实现方案的产品边界，向集进取型和稳定型于一身的平台级解决方案演进。
Sharding-JDBC
定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。</description>
    </item>
    
    <item>
      <title>Apache ShardingSphere社区的探索与拓展</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/community/</guid>
      <description>Apache ShardingSphere社区的探索与拓展 Apache ShardingSphere社区受邀参与了11月9日在清华大学举办的《Apache Event——走进Apache开源软件社区》的分享活动。在活动中Apache ShardingSphere社区的PPMC张亮分享了《Apache ShardingSphere社区的探索与拓展》这个话题，下面呈现分享的主要内容。
01 为什么要做开源 做开源对于个人来讲，能获得两方面的收益：更好的职业生涯和享受乐趣。
-1- 更好的职业生涯
1. 职位需求多。企业对于开源岗位有很强的招聘需求。开源能够给公司带来很多价值，如：通过开源项目搭建云服务平台并提供增值服务、让开源项目本身的质量得以提升、提升公司的是技术影响力等。开源的职位往往与技术和社区本身关联性高、不受地域限制，属于一个比较自由的职位。
2. 自身技能提升。包括技术能力和软技能的提升。通过参与顶级的开源项目，技术的提升自不必说，其他的软技能也会得到相应的提升，如英语、协作能力、运营推广能力等。如果是打造全新的开源项目，从零到一的开创能力也会得到极大的提升。
3. 人际关系拓展。开源参与者的职业生涯将不再仅关注薪水、KPI等与工作本身强相关的事情。纯粹的技术交流、各种会议的分享、写作邀请、甚至资本注入等各种与行业相关的连接会被逐渐扩展，参与国际的开源项目还会认识更多的国际友人。正所谓低头做技术，抬头看世界。参与开源，认识更多的人，为今后职业生涯的发展提供更多可能性。
4. 个人品牌打造。开源的工作，其过程和成果都是公开的，这就意味着参与者的所有努力都可以被任何人在任何时间看得到，是永久留存的记录。而公司内部的私有项目风险比开源项目相对来说要大很多，私有项目的评断标准取决于项目负责人的认可，如果项目责任人不认可，那么参与者的价值就趋近于零。开源项目则不同，正是因为参与者的价值能够在一个公开的平台去展现，价值的评断不取决于一个相对狭小的范围。
-2- 享受乐趣
1. 成长的乐趣。真正喜欢去做一件事情的人，会在成长中体会到乐趣。软件开发行业是要需要从业者发挥自驱力的行业，遵从内心的喜欢编程，是在这个行业中取得成功的捷径。喜欢编程的人，自然能够体会自身成长所带来的乐趣。
2. 成就感。行业的认同，会在成长的同时获得成就感。无论是个人自身的成就感，还是项目提升带来的成就感，都是职业生涯中快乐的源泉。当你所做的东西，被同好者广泛认可的时候，成就感会油然而生。
02 Apache软件基金会项目简介 Apache软件基金会是一个非盈利组织。从1999年至今的20年时间里，产出了无数影响软件行业的项目。在几百个Apache软件基金会项目中，我们可以浏览一下几个非常著名的项目：Apache Tomcat、Apache Commons、Apache Maven、Apache Hadoop、Apache Kafka、Apache Spark、Apache Zookeeper等等。Apache软件基金会的项目成为了开发者日常工作的基石。毫不夸张的说，如果以上项目，您一个都没听说过的话，那么可能很难拿到任何一家公司的Java后端或大数据类Offer。
近年来，来自中国的Apache项目也越来越多了，截止到目前为止，已经有19个来自中国的项目进入了Apache软件基金会，其中有9个项目已经毕业成为顶级项目，还有10个项目正在孵化中。对于没有在西方社会工作过的人来说，参与一个国际化的开源项目的门槛有点高，因此，来自中国的Apache软件基金会项目对于想参与开源的国内同学是一个巨大的福音。这些项目能够提供一个有效的缓冲带，让一些初入社区且找不到门路的同学能够以熟悉的母语快速的进入国际化的开源社区。来自中国的Apache软件基金会项目，与来自西方的Apache软件基金会项目在流程、规范、法务等方面并无不同，唯一的区别是能在社区中找到可以说汉语的人，拉进沟通交流的举例，并进一步的了解Apache社区的运作模式，为以后参与其他国际化项目打好基础。
03 Apache ShardingSphere 简介 Apache ShardingSphere是19个来自中国的Apache软件基金会项目之一，目前正在孵化器中。Apache ShardingSphere是一个微内核且可高度扩展的数据库中间件。它的内核微小而稳定，但却提供可无限扩展的平台，因此它非常适合与开放的社区一起成长，并近乎于无限的拓展其功能范围。
Apache ShardingSphere开源将近4年了，它的外部使用相当广泛，目前有100+公司明确的声明正在使用中，并未声明的公司不计其数，无法准确的统计。已经记录在册的公司涵盖了各行各业，有互联网、互联网金融、在线教育、企业服务，甚至还包括政府机关。Apache ShardingSphere和纯粹从社区兴起的项目略有不同，它是由公司捐助到Apache软件基金会的，在公司内部已经被十分广泛的使用，涵盖京东白条、超级账户、城市计算、秒级监控、京东金融云、京东大数据、京东海外商城等很多系统。相对于自由发展的社区，Apache ShardingSphere也需要承载的稳定性的枷锁。
04 Apache ShardingSphere 社区数据统计 对于一个开源项目来说，项目本身和社区是同样重要的，因此，项目+社区才是组成的Apache ShardingSphere的全部。Apache ShardingSphere是在2018年11月10号正式进入Apache软件基金会孵化器的，至今为止正好一年。这一年来，社区活跃度的社区数据变化还是很明显的。
-1- 邮件列表数据变化
这里只统计dev@shardingsphere.apache.org邮箱，dev邮箱是社区交流问题的主要途径。2019年5月有邮件53封；主题20个；参与人数14人。而且这些数据的统计是包含了GitBox从GitHub转发的15封邮件，那么实际的邮件数量是38封。在2019年9月的统计数据则有了明显的提升，其中邮件148封；主题34个，参与人37人，并且我们已经将GitBox转发的邮件从dev邮件组摘除，而是转移到了notification@shardingsphere.apache.org邮箱。
-2- GitHub数据变化
从项目开源之初，到2018年6月左右的时间，项目整体的提交波峰波谷数据，和我个人的提交数据是几乎吻合的。这说明，在没有进入Apache软件基金会之前，ShardingSphere项目是个人色彩浓重的项目，它的成功与失败，是绑定在个人之上，项目的风险完全集中在一个或几个人身上。对比下近一个月（2019年10月-2019年11月）的GitHub数据，可以看到项目有33个人参与；合并了100个pull requests；关闭了167个issues；新建了36个issues；总共修改了591个文件；其中新增代码12021行；删除代码6577行。可以看到，Apache ShardingSphere已经从个人项目转变为一个社区项目，由社区所掌控的项目风险更小、进展更迅速。GitHub的stars数量在近一年中增长了4000以上，从进入Apache基金会之前的5000+增长到了现在的9000+。
-3- 社区数据变化
在进入Apache孵化器时，ShardingSphere的项目管理委员会成员一共有11人，除了项目管理委员会成员，社区中并未有官方提交者。经过了一年的进展，目前项目管理委员会成员增加了2人，达到了13人；并且新提升了7个官方提交者。一年来，参与项目的贡献者也从37人增长到了88人。参与的人数还在不断的增长中，未来ShardingSphere社区会从这些贡献者中提升更多的官方提交者，也会从官方提交者中提升更多的项目管理委员会成员。
05 Apache ShardingSphere社区的核心思路  1.</description>
    </item>
    
    <item>
      <title>开源推动下的Apache ShardingSphere架构演进</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/evolution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/evolution/</guid>
      <description>本次分享将从 New SQL 切入，重点介绍 ShardingSphere 架构演进和规划，并落到开源与贡献者的关系与发展。从产品生态，开源力量，个人成长发展等角度为大家带来解读和分享。
        </description>
    </item>
    
    <item>
      <title>快讯！Apache ShardingSphere进入CNCF全景图</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/cncf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/cncf/</guid>
      <description>快讯！Apache ShardingSphere进入CNCF全景图 CNCF (Cloud Native Computing Foundation)，是由Google牵头创立的云原生计算开源软件基金会。它致力于云原生（Cloud Native）技术的普及和可持续发展。云原生技术是通过一系列的软件、规范和标准帮助企业和组织，在现代的动态环境（如公共云、私有云和混合云）中构建和运行敏捷的、可扩展的应用程序。容器、微服务、微服务治理、声明式API等都是代表性的云原生技术。
CNCF Landscape (https://github.com/cncf/landscape) 是CNCF中的一个重要项目，它旨在为云原生应用者提供一个资源地图，帮助企业和开发人员快速了解云原生体系的全貌。
CNCF将云原生的生态圈横向划分为五层，并且针对它们又纵向规划出两部分，作为横向五层的共用层。横向划分的五层分别是：应用定义与开发、编排与治理、运行时、供应保障和云设施。纵向划分的两部分是：观察与分析和平台。将这些功能整合起来即是一个完善的云平台服务产品，全景图如下：
&amp;ndash; 以上内容摘自书籍《未来架构:从服务化到云原生》
ShardingSphere 北京时间2019年6月28日，Apache ShardingSphere进入CNCF Landscape。在全景图App Definition Development-Database领域占有一席之地，如下图所示。
Apache ShardingSphere在开源领域及云原生领域会持续拓展，不断精进，构建有机开源生态圈！
我们也希望有更多开源及云原生社区的爱好者能加入我们，共同前进，促进Apache ShardingSphere社区及贡献者们共同成长！
Apache ShardingSphere（Incubating）自2016开源以来，不断精进、不断发展，被越来越多的企业和个人认可：Github上收获8000+的stars，近百家公司企业的成功案例。此外，越来越多的企业和个人也加入到Apache ShardingSphere（Incubating）的开源项目中，为它的成长和发展贡献了巨大力量。</description>
    </item>
    
    <item>
      <title>海量数据下的NewSQL数据库生态构建</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/ecosystem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/ecosystem/</guid>
      <description>伴随着互联网的急速发展，互联网数据的规模也在爆炸式增长。在这种场景下，传统的数据库如何进行变革升级，来满足新的互联网的数据需求？如何借助NewSQL理念，打造分布式数据库集群的生态，来满足业务方对查询性能、大数据量存储、数据安全、弹性扩展等方面的需求？本次分享将针对这些问题，进行细致剖析，并提供较为完整的NewSQL解决方案。
        </description>
    </item>
    
    <item>
      <title>Apache ShardingSphere 5.x 的新功能</title>
      <link>https://shardingsphere.apache.org/blog/cn/videos/newfeature/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/videos/newfeature/</guid>
      <description>Apache ShardingSphere 5.x 的首个版本发布在即。Apache ShardingSphere 从架构设计理念到产品定位都有重大革新。采用了可插拔的方式，使其具备高度灵活、可插拔和可扩展的能力;在产品定位方面，不再以数据分片为内核，而是转向分布式数据库生态的打造。5.x 版本将数据分片、分布式事务、数据库治理等核心功能从项目内核中完全抽离，成为其可插拔生态的一部分。并且通过 SPI 的方式完全开放其生态，将数据迁移、弹性调度、数据加密、影子表等功能完全融入至产品生态中。
        </description>
    </item>
    
    <item>
      <title>Apache ShardingSphere整合Seata AT分布式事务</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/seata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/seata/</guid>
      <description>Apache ShardingSphere整合Seata AT分布式事务 背景知识 Seata是阿里集团和蚂蚁金服联合打造的分布式事务框架，目前版本包含了AT事务和TCC事务。其中AT事务的目标是在微服务架构下，提供增量的事务ACID语意，让用户像使用本地事务一样，使用分布式事务，核心理念同ShardingSphere一脉相承。
Github: https://github.com/seata/seata
Seata AT模型 Seata AT事务模型包含TM(事务管理器)，RM(资源管理器)，TC(事务协调器)。
其中TC是一个独立的服务需要单独部署，TM和RM以jar包的方式同业务应用部署在一起，它们同TC建立长连接，在整个事务生命周期内，保持RPC通信。
其中全局事务的发起方作为TM，全局事务的参与者作为RM ; TM负责全局事务的begin和commit/rollback，RM负责分支事务的执行和commit/rollback。
ShardingSphere分布式事务SPI ShardingSphere提供了一套接入分布式事务的SPI，设计的目标是保证数据分片后，事务的ACID语意。分布式事务的实现目前主要包含两阶段的XA和BASE柔性事务。Seata AT事务作为BASE柔性事务的一种实现，可以无缝接入到ShardingSphere生态中。
两阶段XA事务方面，我们已经整合了Atomikos，Narayana，Bitronix事务管理器，XA事务底层依赖具体的数据库厂商对XA两阶段提交协议的支持，通常XA协议通过在Prepare和Commit阶段进行2PL(2阶段锁)，保证了分布式事务的ACID，通常适用于短事务及非云化环境（云化环境下一次IO操作大概需要20ms，两阶段锁会锁住资源长达40ms，因此事务的TPS会降到25/s左右，非云化环境通常一次IO只需几毫秒，因此锁热点数据的时间相对较低）[1]。
BASE柔性事务方面，目前我们已经完成了对ServiceComb Saga的整合，Saga通过一阶段提交+补偿的方式提高了整体事务的性能，其中补偿的方式同Seata大致相同，即对分片后的物理SQL进行revert来生成补偿的SQL，但Saga模型在理论上不支持隔离级别，适用于对性能要求较高，对一致性要求比较低的业务。Seata AT事务在一阶段提交+补偿的基础上，通过TC的全局锁实现了RC隔离级别的支持，是介于XA和Saga之间的另一种实现。消息柔性事务方面，也欢迎大家参考我们的SPI提供整合的方案。
整合方案 整合Seata AT事务时，需要把TM，RM，TC的模型融入到ShardingSphere 分布式事务的SPI的生态中。在数据库资源上，Seata通过对接DataSource接口，让JDBC操作可以同TC进行RPC通信。同样，ShardingSphere也是面向DataSource接口对用户配置的物理DataSource进行了聚合，因此把物理DataSource二次包装为Seata的DataSource后，就可以把Seata AT事务融入到ShardingSphere的分片中。
在Seata模型中，全局事务的上下文存放在线程变量中，通过扩展服务间的transport，可以完成线程变量的传递，分支事务通过线程变量判断是否加入到整个Seata全局事务中。而ShardingSphere的分片执行引擎通常是按多线程执行，因此整合Seata AT事务时，需要扩展主线程和子线程的事务上下文传递，这同服务间的上下文传递思路完全相同。
Quick Start 我们已经实现了base-seata-raw-jdbc-example，大家可以自行进行尝试。
https://github.com/apache/incubator-shardingsphere-example/tree/dev/sharding-jdbc-example/transaction-example/transaction-base-seata-example/transaction-base-seata-raw-jdbc-example
操作手册：
1.按照seata-work-shop中的步骤，下载并启动seata server。
https://github.com/seata/seata-workshop
参考 Step6 和 Step7即可
2.在每一个分片数据库实例中执行resources/sql/undo_log.sql脚本，创建undo_log表
3.Run YamlConfigurationTransactionExample.java
待优化项 Seata AT事务在Revert SQL时，需要对ShardingSphere分片后的物理SQL进行二次的解析，这里我们需要设计一个SPI，避免SQL二次解析的性能损耗。
参考论文
[1]: Transactions for Distributed Actors in the Cloud
https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/EldeebBernstein-TransactionalActors-MSR-TR-1.pdf</description>
    </item>
    
    <item>
      <title>刚柔并济的开源分布式事务解决方案</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/solution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/solution/</guid>
      <description>刚柔并济的开源分布式事务解决方案 作者 张亮，京东数科数据研发负责人，Apache ShardingSphere发起人 &amp;amp; PPMC
热爱开源，目前主导开源项目ShardingSphere(原名Sharding-JDBC)和Elastic-Job。擅长以java为主分布式架构以及以Kubernetes和Mesos为主的云平台方向，推崇优雅代码，对如何写出具有展现力的代码有较多研究。
目前主要精力投入在将ShardingSphere打造为业界一流的金融级数据解决方案之上。ShardingSphere已经进入Apache孵化器，是京东集团首个进入Apache基金会的开源项目，也是Apache基金会首个分布式数据库中间件。
 姜宁，华为开源能力中心技术专家，Apache ServiceComb项目负责人。前红帽软件首席软件工程师，在企业级开源中间件开发方面有十余年经验，有丰富的Java开发和使用经验，函数式编程爱好者。从2006年开始一直从事Apache开源中间件项目的开发工作，先后参与Apache CXF，Apache Camel，以及Apache ServiceMix的开发。对微服务架构，WebServices，Enterprise Integration Pattern，SOA， OSGi 均有比较深入的研究。
博客地址：https://willemjiang.github.io/
 冯征，红帽软件工程师。2009年加入红帽软件公司，主要从事事务管理器方面的工作，做为核心开发人员参与了 Narayana 和 BlackTie 项目，在与多个应用服务器（Wildfly, Karaf, Tomcat）和框架（Common DBCP, Spring Boot）的事务处理集成方面有过贡献。从2017年开始参与了Apache ServiceComb项目，目前是PMC成员之一。对于分布式事务处理以及微服务环境中的事务处理，有过深入的研究。
导读 相比于数据分片方案的逐渐成熟，集性能、透明化、自动化、强一致、并能适用于各种应用场景于一体的分布式事务解决方案则显得凤毛麟角。基于两（三）阶段提交的分布式事务的性能瓶颈以及柔性事务的业务改造问题，使得分布式事务至今依然是令架构师们头疼的问题。
Apache ShardingSphere（Incubating）不失时机的在2019年初，提供了一个刚柔并济的一体化分布式事务解决方案。如果您的应用系统正在受到这方面的困扰，不妨倒上一杯咖啡，花十分钟阅读此文，说不定会有些收获呢？
背景 数据库事务需要满足ACID（原子性、一致性、隔离性、持久性）4个特性。
  原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。
  一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。
  隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。
  持久性（Durability）指已提交的事务修改数据会被持久保存。
  在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生。
关系型数据库虽然对本地事务提供了完美的ACID原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是分布式事务的重点工作。
本地事务 在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。
两阶段提交 XA协议最早的分布式事务模型是由X/Open国际联盟提出的X/Open Distributed Transaction Processing（DTP）模型，简称XA协议。
基于XA协议实现的分布式事务对业务侵入很小。 它最大的优势就是对使用方透明，用户可以像使用本地事务一样使用基于XA协议的分布式事务。 XA协议能够严格保障事务ACID特性。
严格保障事务ACID特性是一把双刃剑。 事务执行在过程中需要将所需资源全部锁定，它更加适用于执行时间确定的短事务。 对于长事务来说，整个事务进行期间对数据的独占，将导致对热点数据依赖的业务系统并发性能衰退明显。 因此，在高并发的性能至上场景中，基于XA协议两阶段提交类型的分布式事务并不是最佳选择。</description>
    </item>
    
    <item>
      <title>成为Apache官方认可的Committer有什么优势</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/committer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/committer/</guid>
      <description>成为Apache官方认可的Committer有什么优势 什么是Apache软件基金会？ Apache软件基金会（Apache Software Foundation），是当今最具影响力的非盈利性开源软件项目组织，正式成立于1999年，主要由开发者与用户的团体组成。在Apache软件基金会主导下，已有350多个顶级开源项目毕业，包括全球最著名的网络服务器软件Apache HTTP Server。秉持着“开放、创新、社区”的精神，很多Apache项目已经建立起强大成功的生态圈，社区充满活力。
除了许多在信息技术领域十分具有影响力的项目外，Apache许可证（Apache License），Apache贡献者协议许可（CLAs）和开放合作的模式（Apache Way）也在业内有着突出的贡献，其影响力远远扩大到Apache软件基金会以外。
Apache软件基金会如今已成为现代开源软件生态系统的基石。
为什么要成为Apache committer？ 说了这么多，不管大家之前对Apache软件基金会了解到了什么程度，都可以看出，这是一个极具影响力的组织，在业内广受认可。
如果能够成为一名官方承认的committer，不仅是对自己的极大认可，表明自身有能力参与到Apache级的项目开发中，并作出切实的贡献；而且还能够受到业内广泛尊重，无论是对求职还是升职加薪都很有帮助。
简单来说，不管是和其他小伙伴们炫耀，还是写到简历上都倍儿有面子
并且，官方认可的committer还会获取带@apache后缀的邮箱，还能名列Apache网站上
（http://people.apache.org/committer-index.html）
在世界上千百万的工程师中，只有极少数的人才能成为committer拥有这些特权，是不是很诱人呢？
想象一下，小伙伴们浏览Apache网站时看到了你的名字，或者和面试官发邮件时，他们会不会有种不明觉厉的感觉，形象瞬间就高大上了有木有！
如何成为官方认可的committer？ 下面就是本篇文章的重点啦，需要做些什么，才会成为一名官方认可的committer呢？
活跃地参与到Apache项目中，比如Apache ShardingSphere（Incubating）即可。
不如从领个任务练练手开始？目前公布出的任务如下，欢迎领取：
  实现使用Inline表达式对Sharding-SpringBoot进行规则配置
https://github.com/sharding-sphere/sharding-sphere/issues/1686
  实现使用SpringBoot占位符方式对Sharding-SpringBoot进行规则配置
https://github.com/sharding-sphere/sharding-sphere/issues/1687
  我们以后也会定期在GitHub上以issue的方式发布一些开发功能任务， 欢迎通过订阅我们的邮件列表关注，具体方式可参照官网：
http://shardingsphere.io/community/cn/contribute/subscribe/
通过订阅Apache ShardingSphere的邮件列表，还可以了解到Apache ShardingSphere的最新项目进展，功能开发计划，Bug列表等；还能与ShardingSphere开发人员直接对话，讨论您遇到的问题，您的想法和建议等，我们一定会积极回复。
P.S. ShardingSphere最近完成了向Apache过渡的重要一步，正式将官网和GitHub迁移到了Apache网站。
以下是迁移后的网址：
官网（http://shardingsphere.apache.org/）
GitHub（https://github.com/apache/incubator-shardingsphere）
结语 Apache ShardingSphere（Incubating）自2016开源以来，不断精进、不断发展，被越来越多的企业和个人认可：Github上收获6000+的stars，70+公司企业的成功案例。此外，越来越多的企业和个人也加入到Apache ShardingSphere（Incubating）的开源项目中，为它的成长和发展贡献了巨大力量。
我们从未停息过脚步，聆听社区伙伴的需求和建议，不断开发新的、强大的功能，不断使其健壮可靠！
开源不易, 我们却愿向着最终的目标，步履不停！
那么，正在阅读的你，是否可以助我们一臂之力呢？分享、转发、使用、交流，以及加入我们，都是对我们最大的鼓励！
项目地址：
https://github.com/apache/incubator-shardingsphere
更多信息请浏览官网：
http://shardingsphere.apache.org/</description>
    </item>
    
    <item>
      <title>自动化执行引擎</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/engine/</guid>
      <description>自动化执行引擎 今天「剖析Sharding-Sphere系列文章」为大家带来对Sharding-Sphere自动化执行引擎模块的相关介绍。鉴于老板比较喜欢正经的技术文章，所以妹子我尽量用正经又不失肃穆的叙述风格，为大家带来《Sharding-Sphere自动化执行引擎模块》的分享。
传说鱼的记忆只有7秒钟。前段时间刚把这个模块的代码抒写整理完，趁着我还没有失忆之前，先为大家叙述一二，愿对各位看官有所帮助。
「剖析Sharding-Sphere系列文章」是由Sharding-Sphere的核心开发成员亲自操刀向大家介绍和剖析Sharding-Sphere的核心模块、所使用的前沿技术、有价值的经验总结等。这一系列的文章将带您走进Sharding-Sphere的内核世界，获得新知、激发灵感。更希望您关注我们，共同交流切磋，一同前行。
作者介绍 潘娟，京东金融运维DBA，主要负责京东金融生产数据库运维及数据库平台、中间件开发工作。多次参与京东金融6.18、11.11大促活动的护航工作。曾负责京东金融数据库自动化平台设计与开发项目，现专注于Sharding-Sphere分布式数据库中间件开发。乐于在数据库、自动化、分布式、中间件等相关领域进行学习和探索。
概念介绍 Q: 什么叫&amp;quot;自动化执行引擎&amp;rdquo;？
A: 一条SQL的生命周期是：从客户端发起、经过Sharding-Sphere处理、再到底层数据库执行消化。而在Sharding-Sphere里过程则是：SQL解析&amp;ndash;&amp;gt;SQL优化&amp;ndash;&amp;gt;SQL路由&amp;ndash;&amp;gt;SQL改写&amp;ndash;&amp;gt;SQL执行&amp;ndash;&amp;gt;结果归并。自动化执行引擎是为了处理SQL执行问题的，即将路由改写后的真实SQL如何有控制且高效地传送到底层数据库执行。那么直接通过JDBC发送SQL至数据库执行难道行不通吗？还有其他需要考虑吗？答案是：肯定有其他考虑，否则我就不用写这篇文章了。这就体现在它的&amp;quot;自动化&amp;quot;上了。所谓&amp;quot;自动化&amp;rdquo;，其实是为了平衡数据库连接创建与结果归并模式选择问题，为了平衡资源控制与执行效率问题。
需求场景 Q: 为何需要自动化执行引擎呢？
A: 在概念介绍部分，我们介绍了主角-自动化执行引擎。也谈到它的自动化是为了平衡数据库连接创建以及结果归并模式选择问题。这是它诞生的宿命，历史的选择。下面将为大家介绍这两个需要平衡的问题：
1.数据库连接创建
作为一位混娱乐圈的DBA出身的Java coder, 多少还是会从DBA角度考虑问题。比如从资源控制的角度看，业务方访问数据库的连接数量应当有所限制，这能够有效地防止某一业务操作过多地占用资源，从而将数据库连接的资源耗尽，以致于影响其他业务的正常访问。特别是在一个数据库实例中存在较多分表的情况下，一条不包含分片键的逻辑SQL将产生落在同库不同表的大量真实SQL，如果每条真实SQL都占用一个独立的连接，那么一次查询肯定将会占用过多的资源。Sharding-Sphere作为数据库中间层，如果没有控制好数据库连接数量而导致连接暴增、数据库压力过大的话，极有可能被强行背锅。
2.结果归并模式选择
但是从执行效率的角度看，为每个分片查询维持一个独立的数据库连接，可以更加有效地利用多线程来提升执行效率。为每个数据库连接开启独立的线程，可以并行化IO所产生的消耗。独立的数据库连接，能够保持查询结果集的引用以及游标位置，在需要获取相应数据时移动游标即可，避免了过早将查询结果数据加载至内存。这就涉及到了结果归并模式的选择问题。通过上一篇文章《剖析Sharding-Sphere系列——结果归并》介绍，我们知道当前有两种结果归并的模式，分别是：
流式归并：以结果集游标下移进行结果归并的方式，称之为流式归并，它无需将结果数据全数加载至内存，可以有效地节省内存资源，进而减少垃圾回收的频次。
内存归并：以读取内存中加载的结果集进行归并的方式，进行数据对比归并。它需要将结果数据全数加载至内存。
相信只要是智商在线的朋友，一定会选择流式归并来处理结果集。可是，如果无法保证每个分片查询持有一个独立数据库连接的话，那么就需要在复用该数据库连接、获取下一张分表的查询结果集之前，将当前的查询结果集全数加载至内存。因此，即使可以采用流式归并，在此场景下也不得不退化为内存归并。
一方面是对数据库连接资源的控制保护，一方面是采用更优的归并模式达到内存资源节省的目的，如何处理好两者之间的关系，是Sharding-Sphere执行引擎需求解决的问题。具体来说，如果一条SQL在经过Sharding-Sphere的分片后，需要操作某数据库实例下的200张表，那么，是选择创建200个连接并行执行，还是选择创建一个连接串行执行呢？效率与资源控制又应该如何抉择呢？
进化论 针对上述的场景，Sharding-Sphere在3.0.0.M4之前提供了一种解决思路，即提出了连接模式（Connection Mode）的概念，并划分了两种模式：内存限制模式（MEMORY_STRICTLY）和连接限制模式（CONNECTION_STRICTLY）这两种类型。
  内存限制模式。使用此模式的前提是数据库对其一次操作所耗费的连接数量不做限制。如果实际执行的SQL需要对某数据库实例中的200张表做操作，则对每张表创建一个新的数据库连接，并通过多线程的方式并发处理，以达成执行效率最大化。并且在SQL满足条件情况下，优先选择流式归并，以防止出现内存溢出或避免频繁垃圾回收情况。
  连接限制模式。使用此模式的前提是数据库严格控制对其一次操作所耗费的连接数量。如果实际执行的SQL需要对某数据库实例中的200张表做操作，那么只会创建唯一的数据库连接，并对其200张表串行处理。如果分片在不同的数据库，仍然是多线程处理不同库，但每个库的每次操作仍然只创建一个唯一的数据库连接。这样即可以防止对一次请求对数据库连接占用过多所带来的问题。该模式始终选择内存归并。
  内存限制模式适用于OLAP操作，可以通过放宽对数据库连接的限制提升系统吞吐量；连接限制模式适用于OLTP操作，OLTP通常带有分片键，会路由到单一的分片，因此严格控制数据库连接，以保证在线系统数据库资源能够被更多的应用所使用，是明智的选择。
而Sharding-Sphere最终使用何种模式的决定权就交由用户。Sharding-Sphere提供对连接模式的配置，让开发者依据自己业务的实际场景需求选择使用内存限制模式或连接限制模式。
可是，将两难的选择的决定权甩锅给用户，使得用户必须要了解这两种模式的利弊，并依据业务场景需求进行选择。这显然增加了用户对Sharding-Sphere的学习和使用的成本，这并不是一种最优的解决方案。
此外，这种一分为二的处理方案，将两种模式的切换交由静态的初始化配置，缺乏灵活应性。在实际的使用场景中，面对不同SQL以及占位符参数，每次的路由结果是不同的。这就意味着某些操作可能需要使用内存归并，而某些操作则可能选择流式归并更优，它们不应该由用户在Sharding-Sphere启动之前配置好，而更应该根据SQL和占位符参数的场景，来动态的决定连接模式。
像Sharding-Sphere这样，总是站在用户角度考虑问题并且不断优化精进的七道杠青年是一定要进行相关优化调整的，于是自动化执行引擎就进化出来了。
为了降低用户的使用成本以及连接模式动态化这两个问题，Sharding-Sphere提炼出自动化执行引擎的思路，在其内部消化了连接模式的概念。用户无需了解所谓的内存限制模式和连接限制模式是什么，而是交由执行引擎根据当前场景自动选择最优的执行方案。
同时，自动化执行引擎将连接模式的选择粒度细化至每一次SQL的操作。针对每次SQL请求，自动化执行引擎都将根据其路由结果，进行实时的演算和权衡，并自主地采用恰当的连接模式执行，以达到资源控制和效率的最优平衡。针对自动化的执行引擎，用户只需配置maxConnectionSizePerQuery即可，该参数表示一次查询时每个数据库所允许使用的最大连接数，剩余的处理逻辑将由自动化执行引擎为您负责。
实现解析 整个自动化执行引擎的执行流程如下图所示。
在路由改写完成后，我们会得到路由结果，这个结果集主要包含了SQL、SQL的参数集、数据库等信息。其数据结构如下图所示：
执行引擎的执行过程分为准备、执行两个阶段。
 准备阶段  顾名思义，此阶段用于准备执行的数据。它分为结果集分组和执行单元创建两个步骤。
a. 结果集分组
该步骤是实现内化连接模式概念的关键。执行引擎根据maxConnectionSizePerQuery配置项，结合当前路由结果，自动选择恰当的连接模式。具体步骤如下：
  将SQL的路由结果按照数据库的名称进行分组。
  通过下图的公式获得每个数据库实例在maxConnectionSizePerQuery的允许范围内，每个数据库连接需要执行的SQL路由结果组，并演算出本次请求最优的连接模式。
  在maxConnectionSizePerQuery允许的范围内，当一个连接需要执行的请求数量大于1时，意味着当前的数据库连接无法持有相应的数据结果集，则必须采用内存归并；反之，当一个连接需要执行的请求数量等于1时，意味着当前的数据库连接可以持有相应的数据结果集，则可以采用流式归并。
每一次的连接模式的选择，是针对每一个物理数据库的。也就是说，在同一次查询中，如果路由至一个以上的数据库，每个数据库的连接模式不一定一样，它们可能是混合存在的形态。
b. 执行单元创建
该步骤通过上一步骤获得的路由分组结果创建用于执行的单元。执行单元是指为每个路由分组结果创建相应的数据库连接。
当数据库被限制了连接资源数量且线上业务出现大量并发操作时，如果不妥善处理并发获取数据库连接的问题，则很有可能会发送死锁。在多个请求相互等待对方释放数据库连接资源时，就会产生饥饿等待，造成交叉死锁。
举个栗子，假设一次查询需要在某一数据库上获取2个数据库连接，用于路由至一库的2个分表查询。有可能出现查询A已获取到该数据库的1个数据库连接，并等待获取另一个数据库连接；而查询B则也已经获得了该数据库上的1个数据库连接，并同样等待另一个数据库连接的获取。如果数据库连接池的允许最大连接数是2，那么这2个查询请求将永远孤独地等待着彼此，图绘版的解释可能会更便于大家理解：</description>
    </item>
    
    <item>
      <title>剖析Sharding-Sphere系列——结果归并 </title>
      <link>https://shardingsphere.apache.org/blog/cn/material/result/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/result/</guid>
      <description>剖析Sharding-Sphere系列——结果归并 这一系列文章是由SS的核心开发成员亲自操刀向大家介绍和剖析SS的核心模块、所使用的前沿技术、有价值的经验总结等。这一系列的文章将带您走进SS的内核世界，获得新知、激发灵感。更希望您关注我们，共同交流切磋，一同前行。
讲师介绍 张亮，原当当架构部负责人。热爱开源，目前主导两个开源项目Elastic-Job和Sharding-Sphere(Sharding-JDBC)。擅长以java为主分布式架构以及以Kubernetes和Mesos为主的云平台方向，推崇优雅代码，对如何写出具有展现力的代码有较多研究。2018年初加入京东金融，现担任数据研发负责人。目前主要精力投入在将Sharding-Sphere打造为业界一流的金融级数据解决方案之上。
简介 将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端，称为结果归并。
Sharding-Sphere支持的结果归并从功能上分为遍历、排序、分组和分页4种类型，它们是组合而非互斥的关系。从结构划分，可分为流式归并、内存归并和装饰者归并。流式归并和内存归并是互斥的，装饰者归并可以在流式归并和内存归并之上做进一步的处理。
由于从数据库中返回的结果集是逐条返回的，并不需要将所有的数据一次性加载至内存中，因此，在进行结果归并时，沿用数据库返回结果集的方式进行归并，能够极大减少内存的消耗，是归并方式的优先选择。
流式归并是指每一次从结果集中获取到的数据，都能够通过逐条获取的方式返回正确的单条数据，它与数据库原生的返回结果集的方式最为契合。遍历、排序以及流式分组都属于流式归并的一种。
内存归并则是需要将结果集的所有数据都遍历并存储在内存中，再通过统一的分组、排序以及聚合等计算之后，再将其封装成为逐条访问的数据结果集返回。
装饰者归并是对所有的结果集归并进行统一的功能增强，目前装饰者归并只有分页归并这一种类型。
分类 遍历归并 它是最为简单的归并方式。只需将多个数据结果集合并为一个单向链表即可。在遍历完成链表中当前数据结果集之后，将链表元素后移一位，继续遍历下一个数据结果集即可。
排序归并 由于在SQL中存在ORDER BY语句，因此每个数据结果集自身是有序的，因此只需要将数据结果集当前游标指向的数据值进行排序即可。这相当于对多个有序的数组进行排序，归并排序是最适合此场景的排序算法。
Sharding-Sphere在对排序的查询进行归并时，将每个结果集的当前数据值进行比较（通过实现Java的Comparable接口完成），并将其放入优先级队列。每次获取下一条数据时，只需将队列顶端结果集的游标下移，并根据新游标重新进入优先级排序队列找到自己的位置即可。通过一个例子来说明Sharding-Sphere的排序归并，下图是一个通过分数进行排序的示例图。
示例中展示了3张表返回的数据结果集，每个数据结果集已经根据分数排序完毕，但是3个数据结果集之间是无序的。将3个数据结果集的当前游标指向的数据值进行排序，并放入优先级队列，t_score_0的第一个数据值最大，t_score_2的第一个数据值次之，t_score_1的第一个数据值最小，因此优先级队列根据t_score_0，t_score_2和t_score_1的方式排序队列。
下图则展现了进行next调用的时候，排序归并是如何进行的。
通过图中我们可以看到，当进行第一次next调用时，排在队列首位的t_score_0将会被弹出队列，并且将当前游标指向的数据值（也就是100）返回至查询客户端，并且将游标下移一位之后，重新放入优先级队列。而优先级队列也会根据t_score_0的当前数据结果集指向游标的数据值（这里是90）进行排序，根据当前数值，t_score_0排列在队列的最后一位。之前队列中排名第二的t_score_2的数据结果集则自动排在了队列首位。
在进行第二次next时，只需要将目前排列在队列首位的t_score_2弹出队列，并且将其数据结果集游标指向的值返回至客户端，并下移游标，继续加入队列排队，以此类推。
当一个结果集中已经没有数据了，则无需再次加入队列。
可以看到，对于每个数据结果集中的数据有序，而多数据结果集整体无序的情况下，Sharding-Sphere无需将所有的数据都加在至内存即可排序，它使用的是流式归并的方式，每次next仅获取唯一正确的一条数据，极大的节省了内存的消耗。
从另一个角度来说，Sharding-Sphere的排序归并，是在维护数据结果集的纵轴和横轴这两个维度的有序性。纵轴是指每个数据结果集本身，它是天然有序的，它通过包含ORDER BY的SQL所获取。横轴是指每个数据结果集当前游标所指向的值，它需要通过优先级队列来维护其正确顺序。每一次数据结果集当前游标的下移，都需要将该数据结果集重新放入优先级队列排序，而只有排列在队列首位的数据结果集才可能发生游标下移的操作。
分组归并 分组归并的情况最为复杂，它分为流式分组归并和内存分组归并。流式分组归并要求SQL的排序项与分组项的字段以及排序类型（ASC或DESC）必须保持一致，否则只能通过内存归并才能保证其数据的正确性。
举例说明，假设根据科目分片，表结构中包含考生的姓名（为了简单起见，不考虑重名的情况）和分数。通过SQL获取每位考生的总分，可通过如下SQL：
在分组项与排序项完全一致的情况下，取得的数据是连续的，分组所需的数据全数存在于各个数据结果集的当前游标所指向的数据值，因此可以采用流式归并。如下图所示。
进行归并时，逻辑与排序归并类似。下图展现了进行next调用的时候，流式分组归并是如何进行的。
通过图中我们可以看到，当进行第一次next调用时，排在队列首位的t_score_java将会被弹出队列，并且将分组值同为“Jetty”的其他结果集中的数据一同弹出队列。在获取了所有的姓名为“Jetty”的同学的分数之后，进行累加操作，那么，在第一次next调用结束后，取出的结果集是“Jetty”的分数总和。于此同时，所有的数据结果集中的游标都将下移至数据值“Jetty”的下一个不同的数据值，并且根据数据结果集当前游标指向的值进行重排序。因此，包含名字顺着第二位的“John”的相关数据结果集则排在的队列的前列。
流式分组归并与排序归并的区别仅仅在于两点：
1.它会一次性的将多个数据结果集中的分组项相同的数据全数取出。
2.它需要根据聚合函数的类型进行聚合计算。
对于分组项与排序项不一致的情况，由于需要获取分组的相关的数据值并非连续的，因此无法使用流式归并，需要将所有的结果集数据加载至内存中进行分组和聚合。例如，若通过以下SQL获取每位考生的总分并按照分数从高至低排序：
那么各个数据结果集中取出的数据与分数进行排序示例图的上半部分的表结构的原始数据一致，是无法进行流式归并的。
当SQL中只包含分组语句时，根据不同数据库的实现，其排序的顺序不一定与分组顺序一致。但由于排序语句的缺失，则表示此SQL并不在意排序顺序。因此，Sharding-Sphere通过SQL优化的改写，自动增加与分组项一致的排序项，使其能够从消耗内存的内存分组归并方式转化为流式分组归并方案。
无论是流式分组归并还是内存分组归并，对聚合函数的处理都是一致的。聚合函数可以归类为比较、累加和求平均值这3种类型。
比较类型的聚合函数是指MAX和MIN。它们需要对每一个同组的结果集数据进行比较，并且直接返回其最大或最小值即可。
累加类型的聚合函数是指SUM和COUNT。它们需要将每一个同组的结果集数据进行累加。
求平均值的聚合函数只有AVG。它必须通过SQL改写的SUM和COUNT进行计算，相关内容已在SQL改写的内容中涵盖，不再赘述。
分页归并 上文所述的所有归并类型都可能进行分页。分页是追加在其他归并类型之上的装饰器，Sharding-Sphere通过装饰者模式来增加对数据结果集进行分页的能力。分页归并负责将无需获取的数据过滤掉。
Sharding-Sphere的分页功能比较容易让使用者误解，用户通常认为分页归并会占用大量内存。在分布式的场景中，将LIMIT 10000000, 10改写为LIMIT 0, 10000010，才能保证其数据的正确性。用户非常容易产生Sharding-Sphere会将大量无意义的数据加载至内存中，造成内存溢出风险的错觉。其实，通过流式归并的原理可知，会将数据全部加载到内存中的只有内存分组归并这一种情况，而通常来说，进行OLAP的分组SQL，不会产生大量的结果数据，它更多的用于大量的计算，以及少量结果产出的场景。除了内存分组归并这种情况之外，其他情况都通过流式归并获取数据结果集，因此Sharding-Sphere会通过结果集的next方法将无需取出的数据全部跳过，并不会将其存入内存。
但同时需要注意的是，由于排序的需要，大量的数据仍然需要传输到Sharding-Sphere的内存空间。因此，采用LIMIT这种方式分页，并非最佳实践。 由于LIMIT并不能通过索引查询数据，因此如果可以保证ID的连续性，通过ID进行分页是比较好的解决方案，例如：
或通过记录上次查询结果的最后一条记录的ID进行下一页的查询，例如：
小结 归并引擎的整体结构划分如下图所示。</description>
    </item>
    
    <item>
      <title>分布式事务在Sharding-Sphere中的实现</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/realization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/realization/</guid>
      <description>分布式事务在Sharding-Sphere中的实现 讲师简介 赵俊
京东金融
高级Java开发工程师
  多年互联网开发经验，热爱开源技术，对分布式存储有浓厚的兴趣。熟悉ElasticSearch、HBase、Presto、Storm等离线和实时数据处理
  目前主要在Sharding-Sphere团队负责分布式事务的开发
  分布式事务的使用场景 ACID 一切从ACID开始说起。ACID是本地事务所具有的四大特征：
  Atomicity：原子性
事务作为整体来执行，要么全部执行，要么全不执行。
  Consistency：一致性
事务应确保数据从一个一致的状态转变为另一个一致的状态。
  Isolation：隔离性
多个事务并发执行时，一个事务的执行不应影响其他事务的执行。
  Durability：持久性
已提交的事务修改数据会被持久保持。
  关系型数据库的本地事务完美的提供了对ACID的原生支持。但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是本文将要阐述的话题。
CAP和Base理论 对于互联网应用而言，随着访问量和数据量的激增，传统的单体架构模式将无法满足业务的高速发展。这时，开发者需要把单体应用拆分为多个独立的小应用，把单个数据库按照分片规则拆分为多个库和多个表。
数据拆分后，如何在多个数据库节点间保证本地事务的ACID特性则成为一个技术难题，并且由此而衍生出了CAP和BASE经典理论。
CAP理论指出，对于分布式的应用而言，不可能同时满足C（一致性），A（可用性），P（分区容错性），由于网络分区是分布式应用的基本要素，因此开发者需要在C和A上做出平衡。
由于C和A互斥性，其权衡的结果就是BASE理论。
对于大部分的分布式应用而言，只要数据在规定的时间内达到最终一致性即可。我们可以把符合传统的ACID叫做刚性事务，把满足BASE理论的最终一致性事务叫做柔性事务。
一味的追求强一致性，并非最佳方案。对于分布式应用来说，刚柔并济是更加合理的设计方案，即在本地服务中采用强一致事务，在跨系统调用中采用最终一致性。如何权衡系统的性能与一致性，是十分考验架构师与开发者的设计功力的。
业界方法 具体到分布式事务的实现上，业界主要采用了XA协议的强一致规范以及柔性事务的最终一致规范。
XA XA是X/Open CAE Specification (Distributed Transaction Processing)模型中定义的TM（Transaction Manager）与RM（Resource Manager）之间进行通信的接口。
Java中的javax.transaction.xa.XAResource定义了XA接口，它依赖数据库厂商对jdbc-driver的具体实现。
mysql-connector-java-5.1.30的实现可参考：
com.mysql.jdbc.jdbc2.optional.MysqlXAConnection。
在XA规范中，数据库充当RM角色，应用需要充当TM的角色，即生成全局的txId，调用XAResource接口，把多个本地事务协调为全局统一的分布式事务。
一阶段提交：弱XA
弱XA通过去掉XA的Prepare阶段，以达到减少资源锁定范围而提升并发性能的效果。典型的实现为在一个业务线程中，遍历所有的数据库连接，依次做commit或者rollback。弱XA同本地事务相比，性能损耗低，但在事务提交的执行过程中，若出现网络故障、数据库宕机等预期之外的异常，将会造成数据不一致，且无法进行回滚。基于弱XA的事务无需额外的实现成本，因此Sharding-Sphere默认支持。
二阶段提交：2PC
二阶段提交是XA的标准实现。它将分布式事务的提交拆分为2个阶段：prepare和commit/rollback。
开启XA全局事务后，所有子事务会按照本地默认的隔离级别锁定资源，并记录undo和redo日志，然后由TM发起prepare投票，询问所有的子事务是否可以进行提交：当所有子事务反馈的结果为“yes”时，TM再发起commit；若其中任何一个子事务反馈的结果为“no”，TM则发起rollback；如果在prepare阶段的反馈结果为yes，而commit的过程中出现宕机等异常时，则在节点服务重启后，可根据XA recover再次进行commit补偿，以保证数据的一致性。
2PC模型中，在prepare阶段需要等待所有参与子事务的反馈，因此可能造成数据库资源锁定时间过长，不适合并发高以及子事务生命周长较长的业务场景。
Sharding-Sphere支持基于XA的强一致性事务解决方案，可以通过SPI注入不同的第三方组件作为事务管理器实现XA协议，如Atomikos和Narayana。
柔性事务 柔性事务是对XA协议的妥协和补偿，它通过对强一致性要求的降低，已达到降低数据库资源锁定时间的效果。柔性事务的种类很多，可以通过各种不同的策略来权衡使用。
一阶段提交 + 补偿 ：最大努力送达（BED）</description>
    </item>
    
    <item>
      <title>揭秘Sharding-Proxy——面向DBA的数据库中间层</title>
      <link>https://shardingsphere.apache.org/blog/cn/material/proxy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/blog/cn/material/proxy/</guid>
      <description>揭秘Sharding-Proxy——面向DBA的数据库中间层 讲师介绍 张永伦：京东金融运维部高级软件工程师
曾在传统行业工作多年，从事基础软件开发工作。后投身互联网，在京东金融开始了爬虫生涯，感叹互联网数据量之大，但心中仍对偏底层的软件感兴趣。今年有幸加入到Sharding-Sphere，能够做自己感兴趣的事情，希望以后多做些工作，提升自己，回报社区。
大家好，我今天想跟大家分享的是Sharding-Sphere的第二个产品Sharding-Proxy。
在上个月亮相的Sharding-Sphere 3.0.0.M1中首次发布了Sharding-Proxy，希望这次分享能够通过几个优化实践，帮助大家管中窥豹，从几个关键细节想象出Sharding-Proxy的全貌。至于更详细的MySQL协议、IO模型、Netty等议题，以后有机会再和大家专题分享。
一、Sharding-Proxy简介 1. Sharding-Proxy概览 Sharding-Proxy定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。目前先提供MySQL版本，它可以使用任何兼容MySQL协议的访问客户端操作数据（如：MySQLCommandClient、MySQLWorkbench等），对DBA更加友好。
  对应用程序完全透明，可直接当做MySQL使用；
  适用于任何兼容MySQL协议的客户端。
  与其他两个产品（Sharding-JDBC、Sharding-Sidecar）的对比：
它们既可以独立使用，也可以相互配合，以不同的架构模型、不同的切入点，实现相同的功能目标。而其核心功能，如数据分片、读写分离、柔性事务等，都是同一套实现代码。
举个例子，对于仅使用Java为开发技术栈的场景，Sharding-JDBC对各种Java的ORM框架支持度非常高，开发人员可以非常便利地将数据分片能力引入到现有的系统中，并将其部署至线上环境运行，而DBA就可以通过部署一个Sharding-Proxy实例，对数据进行查询和管理。
2. Sharding-Proxy架构 整个架构可以分为前端、后端和核心组件三部分来看：
  前端（Frontend）负责与客户端进行网络通信，采用的是基于NIO的客户端/服务器框架，在Windows和Mac操作系统下采用NIO模型，Linux系统自动适配为Epoll模型，在通信的过程中完成对MySQL协议的编解码；
  核心组件（Core-module）得到解码的MySQL命令后，开始调用Sharding-Core对SQL进行解析、改写、路由、归并等核心功能；
  后端（Backend）与真实数据库的交互暂时借助基于BIO的Hikari连接池。BIO的方式在数据库集群规模很大，或者一主多从的情况下，性能会有所下降。所以未来我们还会提供NIO的方式连接真实数据库。
  这种方式下Proxy的吞吐量将得到极大提高，能够有效应对大规模数据库集群。
二、Sharding-Proxy功能细节 1. PreparedStatement功能实现 我在Sharding-Sphere的第一个任务就是实现Proxy的PreparedStatement功能。据说这是一个高大上的功能，能够预编译SQL提高查询速度和防止SQL注入攻击等。一次服务端预编译，多次查询，降低SQL编译开销，提升了效率，听起来没毛病。然而在做完之后却发现被坑了，SQL执行效率不但没有提高，甚至用肉眼都能看出来比原始的Statement还要慢。
先抛开Proxy不说，我们通过wireshark抓包看看运行PreparedStatement时MySQL协议是如何交互的。
示例代码如下：
代码很容易理解，使用PreparedStatement执行两次查询操作，每次都把参数user_id设置为10。分析抓到的包，JDBC和MySQL之间的协议消息交互如下：
JDBC向MySQL进行了两次查询（Query），MySQL返回给JDBC两次结果（Response），第一条消息不是我们期望的PreparedStatement，SELECT里面也没有问号，这就说明prepare没有生效，至少对MySQL服务来说没有生效。
对于这个问题，我想大家心里都有数，是因为JDBC的url没有设置参数useServerPrepStmts=true，这个参数的作用是让MySQL服务进行prepare。没有这个参数就是让JDBC进行prepare，MySQL完全感知不到，是没有什么意义的。接下来我们在url中加上这个参数：
jdbc:mysql://127.0.0.1:3306/demo_ds?useServerPrepStmts=true 交互过程变成了这样：
初看这是一个正确的流程，第1条消息是PreparedStatement，SELECT里也带问号了，通知MySQL对SQL进行预编译；第2条消息MySQL告诉JDBC准备成功；第3条消息JDBC把参数设置为10；第4条消息MySQL返回查询结果。然而到了第5条，JDBC怎么又发了一遍PreparedStatement？
预期应该是以后的每条查询都只是通过ExecuteStatement传参数的值，这样才能达到一次预编译多次运行的效果。
如果每次都“预编译”，那就相当于没有预编译，而且相对于普通查询，还多了两次消息传递的开销：Response（prepareok）和ExecuteStatement（parameter=10）。看来性能的问题就是出在这里了。
像这样使用PreparedStatement还不如不用，一定是哪里搞错了，于是我开始阅读JDBC源代码，终于发现了另一个需要设置的参数——cachePrepStmts。我们加上这个参数看看会不会发生奇迹：
jdbc:mysql://127.0.0.1:3306/demo_ds? useServerPrepStmts=true&amp;amp;cachePrepStmts=true 果然得到了我们预期的消息流程，而且经过测试，速度也比普通查询快了：
从第5条消息开始，每次查询只传参数值就可以了，终于达到了一次编译多次运行的效果，MySQL的效率得到了提高。而且由于ExecuteStatement只传了参数的值，消息长度上比完整的SQL短了很多，网络IO的效率也得到了提升。
原来cachePrepStmts=true这个参数的意思是告诉JDBC缓存需要prepare的SQL，比如“SELECT * FROM t_order WHERE user_id=?”，运行过一次后，下次再运行就跳过PreparedStatement，直接用ExecuteStatement设置参数值。
明白原理后，就知道该怎么优化Proxy了。Proxy采用的是Hikari数据库连接池，在初始化的时候为其设置上面的两个参数：
config.addDataSourceProperty(&amp;quot;useServerPrepStmts&amp;quot;,&amp;quot;true&amp;quot;); config.addDataSourceProperty(&amp;quot;cachePrepStmts&amp;quot;,&amp;quot;true&amp;quot;); 这样就保证了Proxy和MySQL服务之间的性能。那么Proxy和Client之间的性能如何保证呢？
Proxy在收到Client的PreparedStatement的时候，并不会把这条消息转发给MySQL，因为SQL里的分片键是问号，Proxy不知道该路由到哪个真实数据库。Proxy收到这条消息后只是缓存了SQL，存储在一个StatementId到SQL的Map里面，等收到ExecuteStatement的时候才真正请求数据库。
这个逻辑在优化前是没问题的，因为每一次查询都是一个新的PreparedStatement流程，ExecuteStatement会把参数类型和参数值告诉客户端。
加上两个参数后，消息内容发生了变化，ExecuteStatement在发送第二次的时候，消息体里只有参数值而没有参数类型，Proxy不知道类型就不能正确的取出值。所以Proxy需要做的优化就是在PreparedStatement开始的时候缓存参数类型。
完成以上优化后，Client-Proxy和Proxy-MySQL两侧的消息交互都变成了最后这张图的流程，从第9步开始高效查询。</description>
    </item>
    
  </channel>
</rss>